---
title: "ia_edu"
format: html
editor: visual
---

# IA en educación superior y la ilusión de comprender

La IA cambió de forma simultánea el trabajo académico y el trabajo profesional que intentamos enseñar en educación superior. Esa simultaneidad importa en escuelas de negocio, donde formar a una persona significa prepararla para analizar información incompleta, decidir bajo presión y justificar decisiones frente a otros. En ese entorno, la IA no es solo una herramienta de productividad. También altera qué significa comprender y hacer, porque hoy es posible ejecutar tareas y obtener resultados plausibles sin entender el proceso ni saber por qué una respuesta funciona. Esa posibilidad no equivale a competencia real, ya que sin comprensión no hay base para diagnosticar errores, justificar decisiones ni transferir criterio a problemas nuevos cuando cambian las condiciones.

La discusión suele partir de extremos. Un extremo asume que la IA resolverá casi todo y que su incorporación mejorará por sí sola el aprendizaje. El otro extremo asume que su uso solo puede degradar la formación y vaciar de sentido el esfuerzo académico. Ninguna de las dos lecturas orienta bien el problema. La experiencia en aula sugiere una distinción más precisa. La IA puede acelerar la comprensión o acelerar la ilusión de comprensión.

Esa diferencia se vuelve visible en el tipo de uso. Cuando una persona utiliza IA para obtener un resultado rápido y detenerse ahí, puede producir entregables ordenados y plausibles sin dominar metodología, conceptos ni límites del análisis, y sin comprender los supuestos implícitos que sostienen la respuesta. El resultado puede parecer competente, pero la competencia efectiva sigue ausente. Ahí aparece un riesgo central, una ejecución con apariencia de control que no descansa en comprensión real de lo que se hizo. No se trata de defender una pedagogía del pasado. En un entorno de automatización creciente, la comprensión real es una condición de futuro, porque solo desde ahí se puede innovar, adaptar criterios y producir soluciones nuevas cuando los problemas cambian.

Ese riesgo se agrava porque la salida de la IA suele ser convincente en forma y tono. La respuesta llega rápido, con estructura y seguridad retórica. Esa combinación puede inducir sobreconfianza. No hace falta mala fe para caer en eso. Basta con un entorno que premia velocidad y entrega inmediata. La rapidez, por sí misma, no es el problema. El riesgo aparece cuando la rapidez sustituye la fricción cognitiva que exige aprender. Esta diferencia entre fluidez y aprendizaje durable está bien documentada en educación, como señalan Bjork y Bjork (2011).

También existe la otra cara, y es la que justifica incorporar la IA en educación superior. Hoy es posible hacer tareas que antes eran inviables por tiempo, costo o escala. Un estudiante puede explorar más hipótesis, comparar más enfoques, iterar con mayor velocidad y llegar a proyectos más ambiciosos en menos semanas, y un docente puede diseñar experiencias de aprendizaje con mayor cercanía a problemas reales. Pero ese salto solo produce valor formativo cuando hay conocimiento de base para formular buenas preguntas, distinguir señales de ruido y auditar respuestas con criterio.

Esta reasignación de valor no es completamente nueva en la historia de la tecnología educativa. Con internet se temió que nadie volvería a pensar porque la información estaría siempre disponible. Con calculadoras se temió que la matemática se vaciaría de contenido. El tiempo mostró algo más matizado. Las herramientas no eliminan la necesidad de comprender. Cambian qué habilidades se vuelven centrales para comprender y decidir bien. La diferencia actual es de escala y de tipo de delegación, porque la IA generativa externaliza también tareas cognitivas de mayor nivel y por eso exige rediseñar la evaluación, no solo adaptar hábitos de estudio.

Antes delegábamos búsqueda, cálculo o edición. Ahora también delegamos redacción argumentativa, clasificación semántica y parte de la exploración conceptual inicial. Esa delegación amplía productividad, pero también desplaza el punto crítico de calidad hacia el rastro argumental de las decisiones y la capacidad de defensa de lo presentado. Ahí aparece una oportunidad concreta para la escuela de negocio. Si la evaluación premia solo el entregable final, la IA se vuelve atajo natural. Si la evaluación premia comprensión defendible, la IA se vuelve un asistente de alto valor para aprendizaje real.

Para que ese criterio no quede en una declaración general, el rediseño de evaluación no requiere abandonar la producción de resultados, sino complementarla. Menos peso al documento aislado y más peso a defensa oral en vivo, preguntas cruzadas, explicación de supuestos, justificación metodológica y claridad sobre qué parte del trabajo fue delegada y por qué. En términos prácticos, importa distinguir entre quien usa una caja negra con criterio y quien la usa sin entenderla. También importa evaluar si la persona reconoce límites, riesgos de error y condiciones bajo las cuales su conclusión dejaría de ser válida. El punto es consistente con la literatura de aprendizaje autorregulado, en la que Zimmerman (2002) muestra que aprender exige planificar, monitorear y corregir el propio proceso, no solo presentar un buen producto final.

Esta lógica también protege el uso responsable de la IA. Cuando el estudiante sabe que tendrá que explicar decisiones, argumentar en tiempo real y responder objeciones, prepara el trabajo de otra forma. La herramienta deja de ser sustituto del pensamiento y pasa a ser amplificador del pensamiento. No se trata de prohibir la IA ni de romantizar el esfuerzo manual, sino de evitar que velocidad y profundidad se vuelvan incompatibles en el diseño pedagógico.

En ese marco, el rol docente se vuelve más exigente. Incluye entrenar juicio sobre calidad de evidencia, robustez de inferencias y límites de automatización. Incluye, además, desarrollar una alfabetización en IA que no se confunda con destreza superficial de prompting. Usar IA bien no es obtener una respuesta fluida. Es saber cuándo confiar, cuándo dudar, qué contrastar y cómo justificar.

La discusión de fondo, entonces, no separa tecnología y pedagogía. Las integra. La calidad de la adopción depende menos de la herramienta en sí que del diseño institucional que organiza su uso. Por eso el debate útil para escuelas de negocio no es usar IA o no usar IA. Es cómo usarla para construir competencia real en lugar de apariencia de competencia.

Si ese criterio se mantiene, la IA puede elevar la ambición de la educación superior en vez de degradarla. Puede llevar a proyectos más complejos, preguntas más interesantes y ciclos de aprendizaje más rápidos sin perder rigor. Si ese criterio se debilita, la misma tecnología puede producir una cultura de resultados impecables en forma y vacíos en comprensión. La diferencia entre ambos escenarios no está escrita en la herramienta. Está en las expectativas, en la evaluación y en el tipo de responsabilidad intelectual que la institución decide exigir.

## Referencias

Bjork, E. L., y Bjork, R. A. (2011). Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. En M. A. Gernsbacher, R. W. Pew, L. M. Hough y J. R. Pomerantz (eds.), *Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society* (pp. 56-64). Worth Publishers.

Zimmerman, B. J. (2002). Becoming a self-regulated learner: An overview. *Theory Into Practice*, 41(2), 64-70. https://doi.org/10.1207/S15430421TIP4102_2
